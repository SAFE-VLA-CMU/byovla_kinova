import sys

# Imports
from PIL import Image, ImageFilter
import time

# GPT4-o
from openai import OpenAI
import base64
import requests
import json

# Grounded SAM2
import cv2
import supervision as sv
from supervision.draw.color import ColorPalette

# Try to import utils_groundedSAM2 (may fail due to protobuf issues)
try:
    from utils_groundedSAM2.supervision_utils import CUSTOM_COLOR_MAP
    UTILS_GROUNDED_SAM2_AVAILABLE = True
except Exception as e:
    if "runtime_version" in str(e) or "protobuf" in str(e).lower():
        print("‚ö†Ô∏è  utils_groundedSAM2 not available due to protobuf version conflict")
        print("   This is a known compatibility issue with Kinova API and ML libraries")
        print("   ML functionality will be limited")
        UTILS_GROUNDED_SAM2_AVAILABLE = False
        CUSTOM_COLOR_MAP = None
    else:
        print(f"‚ö†Ô∏è  utils_groundedSAM2 not available: {e}")
        UTILS_GROUNDED_SAM2_AVAILABLE = False
        CUSTOM_COLOR_MAP = None

# Try to import SAM2 modules (may fail due to Hydra version conflicts or protobuf issues)
try:
    from sam2.build_sam import build_sam2
    from sam2.sam2_image_predictor import SAM2ImagePredictor
    SAM2_AVAILABLE = True
except Exception as e:
    if "version_base" in str(e):
        print("‚ö†Ô∏è  SAM2 modules not available due to Hydra version conflict")
        print("   This is a known compatibility issue with older Hydra versions")
        print("   ML functionality will be limited")
        SAM2_AVAILABLE = False
        build_sam2 = None
        SAM2ImagePredictor = None
    elif "runtime_version" in str(e) or "protobuf" in str(e).lower():
        print("‚ö†Ô∏è  SAM2 modules not available due to protobuf version conflict")
        print("   This is a known compatibility issue with Kinova API and ML libraries")
        print("   ML functionality will be limited")
        SAM2_AVAILABLE = False
        build_sam2 = None
        SAM2ImagePredictor = None
    else:
        print(f"‚ö†Ô∏è  SAM2 modules not available: {e}")
        SAM2_AVAILABLE = False
        build_sam2 = None
        SAM2ImagePredictor = None

# Try to import transformers (may fail due to protobuf issues)
try:
    from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection
    TRANSFORMERS_AVAILABLE = True
except Exception as e:
    if "runtime_version" in str(e) or "protobuf" in str(e).lower():
        print("‚ö†Ô∏è  transformers not available due to protobuf version conflict")
        print("   This is a known compatibility issue with Kinova API and ML libraries")
        print("   ML functionality will be limited")
        TRANSFORMERS_AVAILABLE = False
        AutoProcessor = None
        AutoModelForZeroShotObjectDetection = None
    else:
        print(f"‚ö†Ô∏è  transformers not available: {e}")
        TRANSFORMERS_AVAILABLE = False
        AutoProcessor = None
        AutoModelForZeroShotObjectDetection = None

# Inpaint Anything
import torch
import sys
import argparse
import numpy as np
from pathlib import Path
from matplotlib import pyplot as plt

# Try to import lama_inpaint (may not be available)
try:
    from lama_inpaint import inpaint_img_with_lama
    LAMA_INPAINT_AVAILABLE = True
except ImportError as e:
    print("‚ö†Ô∏è  lama_inpaint not available")
    print("   This module is part of Inpaint-Anything and may not be installed")
    print("   Inpainting functionality will be limited")
    LAMA_INPAINT_AVAILABLE = False
    inpaint_img_with_lama = None
except Exception as e:
    print(f"‚ö†Ô∏è  lama_inpaint not available: {e}")
    LAMA_INPAINT_AVAILABLE = False
    inpaint_img_with_lama = None

# Try to import utils (may not be available)
try:
    from utils import dilate_mask
    UTILS_AVAILABLE = True
except ImportError as e:
    print("‚ö†Ô∏è  utils module not available")
    print("   This module is part of Inpaint-Anything and may not be installed")
    print("   Some utility functions will be limited")
    UTILS_AVAILABLE = False
    dilate_mask = None
except Exception as e:
    print(f"‚ö†Ô∏è  utils module not available: {e}")
    UTILS_AVAILABLE = False
    dilate_mask = None

# Kinova API imports (replacing WidowX)
try:
    from kortex_api.TCPTransport import TCPTransport
    from kortex_api.RouterClient import RouterClient
    from kortex_api.SessionManager import SessionManager
    from kortex_api.autogen.messages import Base_pb2, DeviceConfig_pb2, Session_pb2
    from kortex_api.autogen.client_stubs.DeviceManagerClientRpc import DeviceManagerClient
    from kortex_api.autogen.client_stubs.BaseClientRpc import BaseClient
    KINOVA_AVAILABLE = True
except AttributeError as e:
    if "MutableMapping" in str(e):
        print("‚ö†Ô∏è  Kinova API has Python 3.10 compatibility issue")
        print("   This is a known issue with older Kinova API versions")
        print("   Basic functionality will still work")
        KINOVA_AVAILABLE = False
    else:
        raise e
except ImportError as e:
    print(f"‚ö†Ô∏è  Kinova API not available: {e}")
    KINOVA_AVAILABLE = False

import threading

import os
import argparse
from scipy.ndimage import filters
from tqdm import tqdm

# Try to import TextStreamer (may fail due to protobuf issues)
try:
    from transformers import TextStreamer
    TEXTSTREAMER_AVAILABLE = True
except Exception as e:
    if "runtime_version" in str(e) or "protobuf" in str(e).lower():
        print("‚ö†Ô∏è  TextStreamer not available due to protobuf version conflict")
        TEXTSTREAMER_AVAILABLE = False
        TextStreamer = None
    else:
        print(f"‚ö†Ô∏è  TextStreamer not available: {e}")
        TEXTSTREAMER_AVAILABLE = False
        TextStreamer = None

from absl import flags
import random
import pickle
import copy

# Import relevant libraries
# Try to import IPython (may not be available)
try:
    from IPython import display
    IPYTHON_AVAILABLE = True
except ImportError as e:
    print("‚ö†Ô∏è  IPython not available")
    print("   This library is used for display functionality in notebooks")
    print("   Display functionality will be limited")
    IPYTHON_AVAILABLE = False
    display = None
except Exception as e:
    print(f"‚ö†Ô∏è  IPython not available: {e}")
    IPYTHON_AVAILABLE = False
    display = None

import jax

# Try to import tensorflow_datasets (may not be available)
try:
    import tensorflow_datasets as tfds
    TFDS_AVAILABLE = True
except ImportError as e:
    print("‚ö†Ô∏è  tensorflow_datasets not available")
    print("   This library is used for dataset loading")
    print("   Dataset functionality will be limited")
    TFDS_AVAILABLE = False
    tfds = None
except Exception as e:
    print(f"‚ö†Ô∏è  tensorflow_datasets not available: {e}")
    TFDS_AVAILABLE = False
    tfds = None
from typing import Any, Callable, Dict, List, Optional, Tuple, Union, overload

from flax.linen import initializers
from flax.linen.dtypes import promote_dtype
from flax.linen.linear import default_kernel_init
from flax.linen.linear import DenseGeneral
from flax.linen.linear import DotGeneralT
from flax.linen.linear import PrecisionLike
from flax.linen.module import compact
from flax.linen.module import merge_param
from flax.linen.module import Module
from flax.linen.normalization import LayerNorm
import jax
from jax import lax
from jax import random
import jax.numpy as jnp
import random as rn
import os
from itertools import chain
import shutil
import gc

# Try to import psutil (may not be available)
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError as e:
    print("‚ö†Ô∏è  psutil not available")
    print("   This library is used for system monitoring")
    print("   System monitoring functionality will be limited")
    PSUTIL_AVAILABLE = False
    psutil = None
except Exception as e:
    print(f"‚ö†Ô∏è  psutil not available: {e}")
    PSUTIL_AVAILABLE = False
    psutil = None

import tqdm
import matplotlib

# Try to import einops (may not be available)
try:
    import einops
    EINOPS_AVAILABLE = True
except ImportError as e:
    print("‚ö†Ô∏è  einops not available")
    print("   This library is used for tensor operations in deep learning")
    print("   Some ML functionality will be limited")
    EINOPS_AVAILABLE = False
    einops = None
except Exception as e:
    print(f"‚ö†Ô∏è  einops not available: {e}")
    EINOPS_AVAILABLE = False
    einops = None

# Note: tensorflow removed due to protobuf conflicts with Kinova API
# import tensorflow as tf
from absl import flags
import pickle
# Note: Octo model import may need separate environment
# from octo.model.octo_model import OctoModel
from scipy.interpolate import UnivariateSpline

# Kinova Robot Controller Class
class KinovaController:
    """Kinova robot controller replacing WidowX functionality"""
    
    def __init__(self, ip="192.168.2.9", port=10000, credentials=("admin", "admin")):
        self.ip = ip
        self.port = port
        self.credentials = credentials
        
        # Connection objects
        self.transport = None
        self.router = None
        self.session_manager = None
        self.base = None
        
        # Movement parameters
        self.TIMEOUT_DURATION = 20
        
        print(f"ü§ñ Kinova Controller for BYOVLA")
        print(f"   IP: {self.ip}")
        print(f"   Port: {self.port}")
        print(f"   Credentials: {self.credentials}")
        print("=" * 40)
    
    def connect(self):
        """Connect to Kinova arm"""
        try:
            print("üîå Connecting to Kinova robot...")
            
            # Set up API
            self.transport = TCPTransport()
            self.transport.connect(self.ip, self.port)
            self.router = RouterClient(self.transport)
            
            # Create session
            session_info = Session_pb2.CreateSessionInfo()
            session_info.username = self.credentials[0]
            session_info.password = self.credentials[1]
            session_info.session_inactivity_timeout = 60000
            session_info.connection_inactivity_timeout = 2000
            
            print("üìù Creating session...")
            self.session_manager = SessionManager(self.router)
            self.session_manager.CreateSession(session_info)
            print("‚úÖ Session created!")
            
            # Create base client
            self.base = BaseClient(self.router)
            
            # Get current pose
            self.get_current_pose()
            print("‚úÖ Connected successfully!")
            return True
            
        except Exception as e:
            print(f"‚ùå Connection failed: {e}")
            return False
    
    def get_current_pose(self):
        """Get current end-effector pose (replacing get_ee_pose)"""
        try:
            pose = self.base.GetMeasuredCartesianPose()
            # Convert to same format as WidowX for compatibility
            x, y, z = pose.x, pose.y, pose.z
            roll, pitch, yaw = pose.theta_x, pose.theta_y, pose.theta_z
            
            # Get gripper state
            gripper_request = Base_pb2.GripperRequest()
            gripper_request.mode = Base_pb2.GRIPPER_POSITION
            gripper_measure = self.base.GetMeasuredGripperMovement(gripper_request)
            gripper_value = gripper_measure.finger[0].value
            
            # Convert gripper value to binary state (0=closed, 1=open)
            gripper_state = 1 if gripper_value > 0.5 else 0
            
            state = [x, y, z, roll, pitch, yaw, gripper_state]
            return state
        except Exception as e:
            print(f"‚ùå Failed to get pose: {e}")
            return None
    
    def execute_action(self, dx, dy, dz, droll, dpitch, dyaw, dgrasp):
        """Execute action using Kinova API (replacing new_ee_pose)"""
        try:
            # Get current pose
            curr = self.get_current_pose()
            if curr is None:
                return False
            
            x, y, z, roll, pitch, yaw, grasp = curr
            
            # Calculate new pose
            newx, newy, newz, newroll, newpitch, newyaw = (
                x + dx, y + dy, z + dz,
                roll + droll, pitch + dpitch, yaw + dyaw
            )
            
            # Create action
            action = Base_pb2.Action()
            action.name = f"Move to ({newx:.3f}, {newy:.3f}, {newz:.3f})"
            action.application_data = ""
            
            cartesian_pose = action.reach_pose.target_pose
            cartesian_pose.x = newx
            cartesian_pose.y = newy
            cartesian_pose.z = newz
            cartesian_pose.theta_x = newroll
            cartesian_pose.theta_y = newpitch
            cartesian_pose.theta_z = newyaw
            
            # Execute movement
            success = self._execute_movement(action)
            
            # Handle gripper
            if success:
                epsilon = 0.7
                if dgrasp >= epsilon:
                    self._open_gripper()
                else:
                    self._close_gripper()
            
            return success
            
        except Exception as e:
            print(f"‚ùå Action execution failed: {e}")
            return False
    
    def _execute_movement(self, action):
        """Execute movement action with timeout"""
        e = threading.Event()
        notification_handle = self.base.OnNotificationActionTopic(
            self._check_for_end_or_abort(e),
            Base_pb2.NotificationOptions()
        )
        
        try:
            print("   Executing movement...")
            self.base.ExecuteAction(action)
            
            print("   Waiting for completion...")
            finished = e.wait(self.TIMEOUT_DURATION)
            self.base.Unsubscribe(notification_handle)
            
            return finished
                
        except Exception as e:
            print(f"   Movement execution failed: {e}")
            return False
    
    def _check_for_end_or_abort(self, e):
        """Check for action completion"""
        def check(notification, e=e):
            event_name = Base_pb2.ActionEvent.Name(notification.action_event)
            print(f"   üì° Event: {event_name}")
            if (notification.action_event == Base_pb2.ACTION_END or 
                notification.action_event == Base_pb2.ACTION_ABORT):
                e.set()
        return check
    
    def _open_gripper(self):
        """Open gripper"""
        try:
            gripper_command = Base_pb2.GripperCommand()
            finger = gripper_command.gripper.finger.add()
            gripper_command.mode = Base_pb2.GRIPPER_SPEED
            finger.value = 0.1  # Positive to open
            self.base.SendGripperCommand(gripper_command)
            print("   Gripper opened")
        except Exception as e:
            print(f"   Gripper open failed: {e}")
    
    def _close_gripper(self):
        """Close gripper"""
        try:
            gripper_command = Base_pb2.GripperCommand()
            finger = gripper_command.gripper.finger.add()
            gripper_command.mode = Base_pb2.GRIPPER_SPEED
            finger.value = -0.1  # Negative to close
            self.base.SendGripperCommand(gripper_command)
            print("   Gripper closed")
        except Exception as e:
            print(f"   Gripper close failed: {e}")
    
    def disconnect(self):
        """Disconnect from robot"""
        try:
            if self.session_manager:
                self.session_manager.CloseSession()
            if self.transport:
                self.transport.disconnect()
            print("üîå Disconnected from robot")
        except Exception as e:
            print(f"‚ùå Error disconnecting: {e}")

# Image display functions for VLA outputs
def display_vla_results(original_img, obj_inpainted_img, final_img, masks_info=None):
    """Display VLA results with inpainting and masks"""
    plt.figure(figsize=(15, 10))
    
    # Original image
    plt.subplot(2, 3, 1)
    plt.imshow(original_img)
    plt.title("Original Image")
    plt.axis('off')
    
    # Object inpainted image
    plt.subplot(2, 3, 2)
    plt.imshow(obj_inpainted_img)
    plt.title("Objects Inpainted")
    plt.axis('off')
    
    # Final processed image
    plt.subplot(2, 3, 3)
    plt.imshow(final_img)
    plt.title("Final VLA Output")
    plt.axis('off')
    
    # Display masks if available
    if masks_info:
        for i, (mask_name, mask) in enumerate(masks_info.items()):
            if i < 3:  # Show up to 3 masks
                plt.subplot(2, 3, 4 + i)
                plt.imshow(mask, cmap='gray')
                plt.title(f"Mask: {mask_name}")
                plt.axis('off')
    
    plt.tight_layout()
    plt.show()

def save_vla_results(original_img, obj_inpainted_img, final_img, masks_info=None, save_dir="./vla_results"):
    """Save VLA results to files"""
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    
    # Save images
    cv2.imwrite(f"{save_dir}/01_original_image.jpg", cv2.cvtColor(original_img, cv2.COLOR_RGB2BGR))
    cv2.imwrite(f"{save_dir}/02_detected_objects.jpg", cv2.cvtColor(obj_inpainted_img, cv2.COLOR_RGB2BGR))
    cv2.imwrite(f"{save_dir}/03_combined_visualization.jpg", cv2.cvtColor(final_img, cv2.COLOR_RGB2BGR))
    
    # Save masks if available
    if masks_info:
        for mask_name, mask in masks_info.items():
            cv2.imwrite(f"{save_dir}/mask_{mask_name}.png", mask.astype(np.uint8) * 255)
    
    print(f"VLA results saved to {save_dir}")

# Keep all the existing functions from BYOVLA but modify the main execution
# ... existing code ... 

def take_picture(pipeline, rotate=True):
    """
    For taking a picture with Intel Realsense Camera D435
    Rotate was true for our setup, due to mounting orientation
    """
    frames = pipeline.wait_for_frames()
    color = frames.get_color_frame()

    color_data = color.as_frame().get_data()
    np_image = np.asanyarray(color_data)

    # Rotate
    if rotate:
        np_image = cv2.rotate(np_image, cv2.ROTATE_90_CLOCKWISE)
        np_image = cv2.rotate(np_image, cv2.ROTATE_90_CLOCKWISE)
    return np_image

def init_camera(rotate=True):
    """
    Take a few pictures, to initialize camera
    """
    pipeline = rs.pipeline()
    pipeline.start()

    for i in range(5):
        frames = pipeline.wait_for_frames()
        color = frames.get_color_frame()

        color_data = color.as_frame().get_data()
        np_image = np.asanyarray(color_data)

    return pipeline

def warm_filter(img):
    """
    Standard warm filter for images.
    """
    increase_table = UnivariateSpline(x=[0, 64, 128, 255], y=[0, 95, 175, 255])(
        range(256)
    )

    middle_table = UnivariateSpline(x=[0, 64, 128, 255], y=[0, 75, 145, 255])(
        range(256)
    )
    decrease_table = UnivariateSpline(x=[0, 64, 128, 255], y=[0, 55, 105, 255])(
        range(256)
    )
    red_channel, green_channel, blue_channel = cv2.split(img)
    red_channel = cv2.LUT(red_channel, increase_table).astype(np.uint8)
    blue_channel = cv2.LUT(blue_channel, decrease_table).astype(np.uint8)

    filtered_img = cv2.merge((red_channel, green_channel, blue_channel))
    return filtered_img

def perturb_gaussian_noise(image, mask, std=0.25):
    """
    Input:
    image: numpy array of shape (H, W, 3)
    mask: numpy array of shape (H, W) - where to add noise

    Output:
    noised_image: numpy array of shape (H, W, 3)
    """
    # Convert the image to a float32 type
    image = image.astype(np.float32) / 255.0
    mask = mask.astype(np.float32) / 255.0

    # Define the Gaussian noise parameters
    mean = 0
    std_dev = std
    gaussian_noise = np.random.normal(mean, std_dev, image.shape)

    # Add the Gaussian noise to the image
    gaussian_noise[:, :, 0] = np.where(mask > 0, gaussian_noise[:, :, 0], 0)
    gaussian_noise[:, :, 1] = np.where(mask > 0, gaussian_noise[:, :, 1], 0)
    gaussian_noise[:, :, 2] = np.where(mask > 0, gaussian_noise[:, :, 2], 0)
    noisy_image = image + gaussian_noise
    # Clip the values to [0, 1] and convert back to [0, 255]
    noisy_image = np.clip(noisy_image, 0, 1)
    noisy_image = (noisy_image * 255).astype(np.uint8)

    return noisy_image

def perturb_gaussian_blur(image, mask, kernel_size=25):
    # Apply Gaussian blur to the whole image
    # The mask must be 0-255, not 0-1

    mask = mask * 255
    mask = mask.astype(np.uint8)

    image = Image.fromarray(image)
    mask = Image.fromarray(mask)

    blurred_image = image.filter(ImageFilter.GaussianBlur(radius=kernel_size))

    # Composite the original image with the blurred image using the mask
    blurred_region = Image.composite(blurred_image, image, mask)
    blurred_region = np.asarray(blurred_region)
    return blurred_region

def encode_image(image_path):
    """
    Used for GPT4-o API
    """
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")

def grounded_sam2_text(list):
    """
    Input:
    list: list of strings to track with Grounded SAM2
    Output:
    out: string of list elements in grounded SAM2 format
    """
    out = ". ".join(list)
    out += "."
    return out

def get_mask(object_name, class_names, detections):
    """
    Returns mask of object
    """
    obj_index = class_names.index(object_name)
    mask = detections.mask[obj_index]
    return mask

# Note: The following functions would need the actual model files and paths
# For now, I'll create simplified versions that demonstrate the structure

def grounded_sam2(img_path, text, save_annotations, save_directory):
    """
    Simplified version - you'll need to implement with actual models
    """
    if not SAM2_AVAILABLE:
        print("‚ö†Ô∏è  SAM2 not available - using placeholder implementation")
        print(f"   Would process: {img_path}, {text}")
        return None, []
    
    print(f"Grounded SAM2 called with: {img_path}, {text}")
    # Placeholder implementation
    # In real implementation, this would use the actual models
    return None, []

def outpaint_anything(img, mask):
    """
    Simplified version - you'll need to implement with actual models
    """
    if not LAMA_INPAINT_AVAILABLE:
        print("‚ö†Ô∏è  Outpainting not available - lama_inpaint module not found")
        print("   Would process image with mask for outpainting")
        return img
    
    print("Outpaint Anything called")
    # Placeholder implementation
    return img

def gpt4o(img_path, language_instruction):
    """
    Simplified version - you'll need to implement with actual API keys
    """
    print(f"GPT4-o called with: {img_path}, {language_instruction}")
    # Placeholder implementation
    return None

def vlm_refine_output(response):
    """
    Simplified version
    """
    print("VLM refine output called")
    # Placeholder implementation
    return [], []

def object_sensitivities(original_img, class_names_sensitivity, detections_sensitivity, w, thresh, N, language_instruction):
    """
    Simplified version
    """
    print("Object sensitivities called")
    # Placeholder implementation
    return np.array([[True] * len(class_names_sensitivity)]), {}

def background_sensitivities(original_img, class_names_sensitivity, detections_sensitivity, w, thresh, N, language_instruction, perturb_std, save_gs2_directory):
    """
    Simplified version
    """
    print("Background sensitivities called")
    # Placeholder implementation
    return np.array([[True] * len(class_names_sensitivity)]), {}

def inpaint_objects(class_names_sensitivity, detections_sensitivity, sensitivity, img, dilate_size_vla):
    """
    Simplified version
    """
    if not LAMA_INPAINT_AVAILABLE or not UTILS_AVAILABLE:
        print("‚ö†Ô∏è  Object inpainting not available - required modules not found")
        print("   Would inpaint objects based on sensitivity")
        return img
    
    print("Inpaint objects called")
    # Placeholder implementation
    return img

def inpaint_backgrounds(class_names, detections, perturb_std, img, w, N, n_steps, thresh, curr_sensitivity):
    """
    Simplified version
    """
    if not LAMA_INPAINT_AVAILABLE or not UTILS_AVAILABLE:
        print("‚ö†Ô∏è  Background inpainting not available - required modules not found")
        print("   Would inpaint backgrounds based on sensitivity")
        return img
    
    print("Inpaint backgrounds called")
    # Placeholder implementation
    return img

if __name__ == "__main__":
    # Initialize Kinova robot instead of WidowX
    print("üöÄ BYOVLA with Kinova Robot")
    print("=" * 40)
    
    # Check Kinova API availability
    if not KINOVA_AVAILABLE:
        print("‚ö†Ô∏è  Kinova API not available due to compatibility issues")
        print("   Running in simulation mode with placeholder robot control")
        bot = None
    else:
        # Create Kinova controller
        try:
            bot = KinovaController()
            
            # Connect to robot
            if not bot.connect():
                print("‚ùå Failed to connect to Kinova robot - exiting")
                sys.exit(1)
        except Exception as e:
            print(f"‚ö†Ô∏è  Kinova controller creation failed: {e}")
            print("   Running in simulation mode")
            bot = None
    
    try:
        # Camera Setup (if available)
        try:
            import pyrealsense2 as rs
            pipeline = init_camera()
            camera_available = True
            print("‚úÖ Camera initialized")
        except ImportError:
            print("‚ö†Ô∏è  pyrealsense2 not available - using placeholder images")
            camera_available = False
            pipeline = None
        
        # Environment Variables
        language_instruction = "Pick up the red object"  # Example instruction
        n_steps = 4  # action chunk
        
        # Initialize Octo model (you'll need to set up the actual model)
        try:
            # Try to import Octo model (may not be available due to protobuf conflicts)
            from octo.model.octo_model import OctoModel
            model = OctoModel.load_pretrained("hf://rail-berkeley/octo-base")
            task = model.create_tasks(texts=[language_instruction])
            octo_available = True
            print("‚úÖ Octo model loaded")
        except ImportError as e:
            print(f"‚ö†Ô∏è  Octo model not available due to import error: {e}")
            print("   This is likely due to protobuf version conflicts with Kinova API")
            octo_available = False
            model = None
            task = None
        except Exception as e:
            if "runtime_version" in str(e) or "protobuf" in str(e).lower():
                print("‚ö†Ô∏è  Octo model not available due to protobuf version conflict")
                print("   This is a known compatibility issue with Kinova API and ML libraries")
                octo_available = False
                model = None
                task = None
            else:
                print(f"‚ö†Ô∏è  Octo model not available: {e}")
                octo_available = False
                model = None
                task = None
        
        # Parameters
        thresh = 0.002
        w = np.array([1, 1, 1, 0, 0, 0, 0])
        N = 5
        dilate_size_vla = 10
        perturb_std = 0.075
        
        # Create results directory
        results_dir = "./vla_results"
        if not os.path.exists(results_dir):
            os.makedirs(results_dir)
        
        # Take initial picture
        if camera_available:
            init_img = take_picture(pipeline)
            print("üì∏ Initial image captured")
        else:
            # Create a placeholder image for demonstration
            init_img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            print("üì∏ Using placeholder image")
        
        # Save initial image
        init_img_path = f"{results_dir}/initial_image.jpg"
        cv2.imwrite(init_img_path, cv2.cvtColor(init_img, cv2.COLOR_RGB2BGR))
        
        # Simulate VLA processing (since models aren't available)
        print("\nüîç Simulating VLA processing...")
        
        # Create example masks for demonstration
        h, w = init_img.shape[:2]
        mask1 = np.zeros((h, w), dtype=np.uint8)
        mask1[100:200, 150:250] = 1  # Example object mask
        
        mask2 = np.zeros((h, w), dtype=np.uint8)
        mask2[300:400, 400:500] = 1  # Example background mask
        
        # Simulate object inpainting
        obj_inpainted = init_img.copy()
        obj_inpainted[mask1 > 0] = [128, 128, 128]  # Gray out objects
        
        # Simulate background inpainting
        final_img = obj_inpainted.copy()
        final_img[mask2 > 0] = [200, 200, 200]  # Light gray backgrounds
        
        # Apply warm filter
        final_img = warm_filter(final_img)
        
        # Display results
        print("\nüñºÔ∏è  Displaying VLA results...")
        masks_info = {
            "object_1": mask1,
            "background_1": mask2
        }
        
        # Display the results
        display_vla_results(init_img, obj_inpainted, final_img, masks_info)
        
        # Save the results
        save_vla_results(init_img, obj_inpainted, final_img, masks_info, results_dir)
        
        # Robot movement demonstration
        if octo_available and bot is not None:
            print("\nü§ñ Running robot actions with Kinova...")
            
            # Get current pose
            curr_pose = bot.get_current_pose()
            if curr_pose:
                print(f"üìç Current pose: {curr_pose}")
                
                # Example action: small movement
                print("üîÑ Executing example action...")
                success = bot.execute_action(0.05, 0, 0, 0, 0, 0, 0)
                if success:
                    print("‚úÖ Action completed successfully")
                else:
                    print("‚ùå Action failed")
                
                # Return to original position
                print("üîÑ Returning to original position...")
                success = bot.execute_action(-0.05, 0, 0, 0, 0, 0, 0)
                if success:
                    print("‚úÖ Return movement completed")
                else:
                    print("‚ùå Return movement failed")
            else:
                print("‚ùå Could not get current pose")
        elif bot is None:
            print("‚ö†Ô∏è  Skipping robot actions (Kinova API not available)")
        else:
            print("‚ö†Ô∏è  Skipping robot actions (Octo model not available)")
        
        print("\nüéâ BYOVLA with Kinova completed successfully!")
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # Cleanup
        if bot is not None:
            bot.disconnect()
        print("\nüßπ Cleanup completed") 